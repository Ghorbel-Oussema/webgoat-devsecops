name: DevSecOps Scan (Build + SAST + DAST + ETL + Quick AI)

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]

permissions:
  contents: read
  security-events: write
  actions: read
  packages: write

# OPTIONAL SECRETS:
#   SEMGREP_APP_TOKEN (optional)
#   OPENAI_API_KEY (optional - only if you call external model)
#
# OPTIONAL (later, for permanent storage):
#   MINIO_ENDPOINT
#   MINIO_ACCESS_KEY
#   MINIO_SECRET_KEY
#   MINIO_BUCKET
#   PGHOST, PGPORT, PGDATABASE, PGUSER, PGPASSWORD

jobs:
  pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 90

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Compute image name (lowercase)
        run: |
          echo "IMAGE=ghcr.io/${GITHUB_REPOSITORY,,}" >> $GITHUB_ENV
          echo "TAG_SHA=${GITHUB_SHA}" >> $GITHUB_ENV

      - name: Setup Java 21
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: "21"
          cache: maven

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Prepare folders
        run: |
          mkdir -p reports/sast/semgrep reports/sast/bearer
          mkdir -p reports/dast/zap reports/dast/nuclei reports/dast/wapiti
          mkdir -p reports/ai ai
          mkdir -p reports/meta

      # =========================
      # 1) Build JAR (needed by Dockerfile)
      # =========================
      - name: Build jar (skip tests)
        run: |
          mvn --no-transfer-progress -DskipTests clean package
          ls -la target || true

      # =========================
      # 2) Build & Push Docker image to GHCR
      # =========================
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build & push image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile
          push: true
          platforms: linux/amd64
          tags: |
            ${{ env.IMAGE }}:latest
            ${{ env.IMAGE }}:${{ env.TAG_SHA }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      # =========================
      # 3) SAST - Semgrep (JSON + SARIF)
      # =========================
      - name: Install Semgrep
        run: |
          python -m pip install --upgrade pip
          pip install semgrep

      - name: Semgrep scan (JSON + SARIF)
        env:
          SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}
        run: |
          semgrep --config p/security-audit --sarif -o reports/sast/semgrep/semgrep.sarif . || true
          semgrep --config p/security-audit --json  -o reports/sast/semgrep/semgrep.json  . || true

      - name: Upload Semgrep SARIF to GitHub Security
        if: always() && hashFiles('reports/sast/semgrep/semgrep.sarif') != ''
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: reports/sast/semgrep/semgrep.sarif

      # =========================
      # 4) SAST - Bearer (JSON + SARIF)
      # =========================
      - name: Bearer scan (JSON + SARIF)
        run: |
          docker run --rm -v "$PWD:/repo" bearer/bearer:latest \
            scan /repo --format json --output /repo/reports/sast/bearer/bearer.json || true
          docker run --rm -v "$PWD:/repo" bearer/bearer:latest \
            scan /repo --format sarif --output /repo/reports/sast/bearer/bearer.sarif || true

      - name: Upload Bearer SARIF to GitHub Security
        if: always() && hashFiles('reports/sast/bearer/bearer.sarif') != ''
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: reports/sast/bearer/bearer.sarif

      # =========================
      # 5) Start staging using the image built in this run
      # =========================
      - name: Start WebGoat container
        run: |
          docker run -d --name webgoat \
            -p 8080:8080 -p 9090:9090 \
            $IMAGE:$TAG_SHA
          docker ps

      - name: Wait for WebGoat
        run: |
          for i in $(seq 1 60); do
            if curl -fsS http://127.0.0.1:8080/WebGoat/actuator/health >/dev/null; then
              echo "WebGoat is up!"
              exit 0
            fi
            sleep 5
          done
          echo "WebGoat not ready" >&2
          docker logs webgoat || true
          exit 1

      # =========================
      # 6) DAST - ZAP (HTML + JSON + XML)
      # =========================
      - name: ZAP Baseline Scan
        run: |
          docker run --rm --network host \
            -v "$PWD/reports/dast/zap:/zap/wrk" \
            ghcr.io/zaproxy/zaproxy:stable \
            zap-baseline.py \
              -t http://127.0.0.1:8080/WebGoat \
              -r zap-report.html \
              -J zap-report.json \
              -x zap-report.xml || true

      # =========================
      # 7) DAST - Nuclei (JSONL)
      # =========================
      - name: Nuclei scan (JSONL)
        run: |
          docker run --rm --network host \
            -v "$PWD/reports/dast/nuclei:/out" \
            projectdiscovery/nuclei:latest \
            -u http://127.0.0.1:8080/WebGoat \
            -severity low,medium,high,critical \
            -jsonl -o /out/nuclei.jsonl || true

      # =========================
      # 8) DAST - Wapiti (HTML)
      # =========================
      - name: Wapiti scan (HTML)
        run: |
          docker run --rm --network host \
            -v "$PWD/reports/dast/wapiti:/out" \
            cyberwatch/wapiti:latest \
            wapiti -u http://127.0.0.1:8080/WebGoat -f html -o /out/wapiti.html || true

      - name: Stop WebGoat
        if: always()
        run: docker rm -f webgoat || true

      # =========================
      # 9) ETL + Quick AI (unified JSON)
      # =========================
      - name: Create ETL/AI script
        run: |
          cat > ai/unify.py <<'PY'
          import json
          from pathlib import Path

          def load_json(p: Path):
              try:
                  return json.loads(p.read_text(encoding="utf-8"))
              except Exception:
                  return None

          def load_jsonl(p: Path):
              out=[]
              try:
                  for line in p.read_text(encoding="utf-8").splitlines():
                      line=line.strip()
                      if not line:
                          continue
                      try:
                          out.append(json.loads(line))
                      except Exception:
                          pass
              except Exception:
                  pass
              return out

          def main():
              base = Path("reports")
              unified = {
                  "meta": {
                      "repo": (Path(".git/config").read_text(errors="ignore") if Path(".git/config").exists() else ""),
                  },
                  "sast": {
                      "semgrep": load_json(base/"sast/semgrep/semgrep.json") or {},
                      "bearer":  load_json(base/"sast/bearer/bearer.json") or {},
                  },
                  "dast": {
                      "zap":     load_json(base/"dast/zap/zap-report.json") or {},
                      "nuclei":  load_jsonl(base/"dast/nuclei/nuclei.jsonl"),
                  },
                  "ai_summary": {
                      "note": "placeholder - replace with your ML/NLP inference"
                  }
              }

              (base/"ai").mkdir(parents=True, exist_ok=True)
              (base/"ai/ai_unified_report.json").write_text(
                  json.dumps(unified, indent=2, ensure_ascii=False),
                  encoding="utf-8"
              )
              print("OK: reports/ai/ai_unified_report.json")

          if __name__ == "__main__":
              main()
          PY

      - name: Run ETL/AI
        run: |
          python ai/unify.py
          ls -la reports/ai || true

      # =========================
      # 10) Upload ONE artifact ZIP (GitHub)
      # =========================
      - name: Upload devsecops reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: devsecops-reports
          path: reports
          retention-days: 14
