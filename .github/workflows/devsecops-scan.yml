name: DevSecOps Scan

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]

permissions:
  contents: read
  security-events: write
  actions: read
  packages: write

# OPTIONAL SECRETS:
#   SEMGREP_APP_TOKEN
#   SONAR_HOST_URL
#   SONAR_TOKEN

jobs:
  scan:
    runs-on: ubuntu-latest
    timeout-minutes: 90

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # ---------- Vars ----------
      - name: Compute image name (lowercase)
        run: |
          echo "IMAGE=ghcr.io/${GITHUB_REPOSITORY,,}" >> $GITHUB_ENV
          echo "TAG_SHA=${GITHUB_SHA}" >> $GITHUB_ENV

      # ---------- Toolchains ----------
      - name: Setup Java 21
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: "21"
          cache: maven

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Detect Node (package.json)
        id: detect_node
        run: |
          if [ -f package.json ]; then
            echo "has_node=true" >> $GITHUB_OUTPUT
          else
            echo "has_node=false" >> $GITHUB_OUTPUT
          fi

      # ---------- Prepare folders ----------
      - name: Prepare folders
        run: |
          mkdir -p reports/meta
          mkdir -p reports/sast/semgrep reports/sast/bearer reports/sast/node reports/sast/sonar
          mkdir -p reports/dast/zap reports/dast/nuclei reports/dast/wapiti
          mkdir -p reports/ai ai

      # =========================
      # 1) Build JAR
      # =========================
      - name: Build jar (skip tests)
        run: |
          mvn --no-transfer-progress -DskipTests clean package
          ls -la target || true

      # =========================
      # 2) Build & Push Docker image to GHCR
      # =========================
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build & push image (latest + sha)
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile
          push: true
          platforms: linux/amd64
          tags: |
            ${{ env.IMAGE }}:latest
            ${{ env.IMAGE }}:${{ env.TAG_SHA }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      # =========================
      # 3) SAST - Semgrep (JSON + SARIF)
      # =========================
      - name: Install Semgrep
        run: |
          python -m pip install --upgrade pip
          pip install semgrep

      - name: Semgrep scan (JSON + SARIF)
        env:
          SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}
        run: |
          semgrep --config p/security-audit --sarif -o reports/sast/semgrep/semgrep.sarif . || true
          semgrep --config p/security-audit --json  -o reports/sast/semgrep/semgrep.json  . || true

      - name: Upload Semgrep SARIF to GitHub Security
        if: always() && hashFiles('reports/sast/semgrep/semgrep.sarif') != ''
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: reports/sast/semgrep/semgrep.sarif

      # =========================
      # 4) SAST - CodeQL (Java)
      # =========================
      - name: Initialize CodeQL
        uses: github/codeql-action/init@v4
        with:
          languages: java
          queries: security-extended

      - name: Autobuild (CodeQL)
        uses: github/codeql-action/autobuild@v4

      - name: Analyze (CodeQL)
        uses: github/codeql-action/analyze@v4
        with:
          category: "/language:java"

      # =========================
      # 5) SAST - Bearer (JSON + SARIF)
      # Fix: avoid permission issue + upload only if SARIF valid
      # =========================
      - name: Bearer scan (JSON + SARIF) - fixed
        run: |
          set -eux
          mkdir -p reports/sast/bearer

          docker run --rm -v "$PWD:/repo" bearer/bearer:latest \
            scan /repo --format json > reports/sast/bearer/bearer.json || true

          docker run --rm -v "$PWD:/repo" bearer/bearer:latest \
            scan /repo --format sarif > reports/sast/bearer/bearer.sarif || true

          # If SARIF empty or invalid, remove it to skip upload
          if [ ! -s reports/sast/bearer/bearer.sarif ]; then
            rm -f reports/sast/bearer/bearer.sarif
          else
            if ! grep -q '"version"' reports/sast/bearer/bearer.sarif || ! grep -q '"runs"' reports/sast/bearer/bearer.sarif; then
              echo "Bearer SARIF not valid -> skipping upload"
              rm -f reports/sast/bearer/bearer.sarif
            fi
          fi

      - name: Upload Bearer SARIF to GitHub Security
        if: always() && hashFiles('reports/sast/bearer/bearer.sarif') != ''
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: reports/sast/bearer/bearer.sarif

      # =========================
      # 6) OPTIONAL - SonarQube
      # =========================
      - name: SonarQube Scan (optional)
        env:
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        run: |
          if [ -z "${SONAR_HOST_URL}" ] || [ -z "${SONAR_TOKEN}" ]; then
            echo "SonarQube secrets not set -> skipping"
            exit 0
          fi

          mvn --no-transfer-progress -DskipTests sonar:sonar \
            -Dsonar.host.url="${SONAR_HOST_URL}" \
            -Dsonar.login="${SONAR_TOKEN}" || true

      # =========================
      # 7) Start WebGoat (image built in this run)
      # =========================
      - name: Start WebGoat container
        run: |
          docker run -d --name webgoat \
            -p 8080:8080 -p 9090:9090 \
            $IMAGE:$TAG_SHA
          docker ps

      - name: Wait for WebGoat
        run: |
          set -eux
          for i in $(seq 1 80); do
            if curl -fsS http://127.0.0.1:8080/WebGoat/actuator/health >/dev/null; then
              echo "WebGoat is up!"
              exit 0
            fi
            sleep 5
          done
          echo "WebGoat not ready" >&2
          docker logs webgoat || true
          exit 1

      - name: Smoke test target
        run: |
          set -eux
          curl -I http://127.0.0.1:8080/WebGoat/ | head
          curl -fsS http://127.0.0.1:8080/WebGoat/actuator/health | cat

      # =========================
      # 8) DAST - ZAP (baseline) via same network namespace as WebGoat
      # =========================
      - name: ZAP Baseline Scan (HTML + JSON + XML) [container network]
        run: |
          set -eux
          docker run --rm --network container:webgoat \
            -v "$PWD/reports/dast/zap:/zap/wrk" \
            ghcr.io/zaproxy/zaproxy:stable \
            zap-baseline.py \
              -t http://127.0.0.1:8080/WebGoat/ \
              -r zap-report.html \
              -J zap-report.json \
              -x zap-report.xml \
              -I || true

          # Debug + ensure JSON is not empty (so your ETL doesn't get blanks)
          ls -lah reports/dast/zap || true
          if [ ! -s reports/dast/zap/zap-report.json ]; then
            echo '{"meta":{"tool":"zap","note":"empty output (no alerts or scan failed)"},"alerts":[]}' > reports/dast/zap/zap-report.json
          fi

      # =========================
      # 9) DAST - Nuclei via same network namespace as WebGoat
      # =========================
      - name: Nuclei scan (JSONL + SARIF) [container network]
        run: |
          set -eux
          docker run --rm --network container:webgoat \
            -v "$PWD/reports/dast/nuclei:/out" \
            projectdiscovery/nuclei:latest \
            -u http://127.0.0.1:8080/WebGoat/ \
            -t http/misconfiguration/ \
            -t http/exposures/ \
            -t http/vulnerabilities/ \
            -severity low,medium,high,critical \
            -jsonl -o /out/nuclei.jsonl || true

          docker run --rm --network container:webgoat \
            -v "$PWD/reports/dast/nuclei:/out" \
            projectdiscovery/nuclei:latest \
            -u http://127.0.0.1:8080/WebGoat/ \
            -t http/misconfiguration/ \
            -t http/exposures/ \
            -t http/vulnerabilities/ \
            -severity low,medium,high,critical \
            -sarif-export /out/nuclei.sarif || true

          ls -lah reports/dast/nuclei || true
          # nuclei.jsonl can be 0 lines (no matches) â€” we keep it valid, but not empty for your pipeline:
          if [ ! -s reports/dast/nuclei/nuclei.jsonl ]; then
            echo '{"meta":{"tool":"nuclei","note":"no matches or scan failed"}}' > reports/dast/nuclei/nuclei.jsonl
          fi

      - name: Upload Nuclei SARIF to GitHub Security
        if: always() && hashFiles('reports/dast/nuclei/nuclei.sarif') != ''
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: reports/dast/nuclei/nuclei.sarif

      # =========================
      # 10) DAST - Wapiti via same network namespace as WebGoat
      # =========================
      - name: Wapiti scan (HTML + JSON) [container network]
        run: |
          set -eux
          docker run --rm --network container:webgoat \
            -v "$PWD/reports/dast/wapiti:/out" \
            cyberwatch/wapiti:latest \
            wapiti -u http://127.0.0.1:8080/WebGoat/start.mvc \
              -m sql,xss,file,xxe \
              -l 2 -d 3 \
              -f html -o /out/wapiti.html || true

          docker run --rm --network container:webgoat \
            -v "$PWD/reports/dast/wapiti:/out" \
            cyberwatch/wapiti:latest \
            wapiti -u http://127.0.0.1:8080/WebGoat/start.mvc \
              -m sql,xss,file,xxe \
              -l 2 -d 3 \
              -f json -o /out/wapiti.json || true

          ls -lah reports/dast/wapiti || true
          if [ ! -s reports/dast/wapiti/wapiti.json ]; then
            echo '{"meta":{"tool":"wapiti","note":"empty output (no vulns or scan failed)"},"vulnerabilities":[]}' > reports/dast/wapiti/wapiti.json
          fi

      # =========================
      # 11) Debug final (sizes)
      # =========================
      - name: Debug DAST sizes (final)
        if: always()
        run: |
          echo "== ZAP bytes ==";    wc -c reports/dast/zap/zap-report.json || true
          echo "== Nuclei lines =="; wc -l reports/dast/nuclei/nuclei.jsonl || true
          echo "== Wapiti bytes =="; wc -c reports/dast/wapiti/wapiti.json || true


      # =========================
      # 11) ETL (unified JSON)
      # =========================
      - name: Create ETL script (unify)
        run: |
          cat > ai/unify.py <<'PY'
          import json
          from pathlib import Path

          def load_json(path: Path, default):
            try:
              return json.loads(path.read_text(encoding="utf-8"))
            except Exception:
              return default

          def load_jsonl(path: Path):
            out=[]
            try:
              for line in path.read_text(encoding="utf-8").splitlines():
                line=line.strip()
                if not line:
                  continue
                try:
                  out.append(json.loads(line))
                except Exception:
                  pass
            except Exception:
              pass
            return out

          def safe_read(path: Path):
            try:
              return path.read_text(encoding="utf-8", errors="ignore")
            except Exception:
              return ""

          def main():
            base = Path("reports")
            unified = {
              "meta": {
                "repo": safe_read(Path(".git/config")),
                "generated_from": "github-actions",
              },
              "sast": {
                "semgrep": load_json(base/"sast/semgrep/semgrep.json", {}),
                "bearer":  load_json(base/"sast/bearer/bearer.json", {}),
              },
              "dast": {
                "zap":     load_json(base/"dast/zap/zap-report.json", {}),
                "nuclei":  load_jsonl(base/"dast/nuclei/nuclei.jsonl"),
                "wapiti":  load_json(base/"dast/wapiti/wapiti.json", {}),
              },
              "ai_summary": {
                "note": "placeholder (later: anomaly detection + NLP recommendations)"
              }
            }
            (base/"ai").mkdir(parents=True, exist_ok=True)
            (base/"ai/ai_unified_report.json").write_text(
              json.dumps(unified, indent=2, ensure_ascii=False),
              encoding="utf-8"
            )
            print("OK: reports/ai/ai_unified_report.json")

          if __name__ == "__main__":
            main()
          PY

      - name: Run ETL
        run: |
          python ai/unify.py
          echo "=== reports tree ==="
          ls -R reports || true

      # =========================
      # 12) Upload ONE artifact ZIP
      # =========================
      - name: Upload devsecops reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: devsecops-reports
          path: reports
          retention-days: 14
